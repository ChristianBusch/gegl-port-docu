\documentclass[10pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[ngerman]{babel}
\selectlanguage{ngerman}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{booktabs}

\usepackage{algorithm}
\floatname{algorithm}{Algorithmus}
\usepackage[noend]{algpseudocode}
\usepackage{listings}
\lstset{language=C,stepnumber=1,numbers=left,breaklines=true}
\usepackage[shortcuts]{extdash}	% trenne auch Worte, die einen Bindestrich enthalten
\providecommand{\abs}[1]{\lvert#1\rvert}
\providecommand{\norm}[1]{\lVert#1\rVert}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{color}
\newcommand{\algorithmautorefname}{Algorithmus}

\hyphenation{
RGBA
}

\begin{document}

\author{Christian Busch
\and
Igor Karlinskiy
\and
Oleksandr Khomenko
\and
Sascha Denis Knöpfle
}
\title{Portierung und Parallelisierung mehrerer Filter von GIMP nach GEGL}
\maketitle

\section{Einleitung}
Das Anwenden von Filtern auf Bilddaten ist ein häufiger Anwendungsfall für Parallelisierung. Hierbei muss oft ein und dieselbe Operation für jeden Pixel des Ausgabebildes angewandt werden. Somit lässt sich relativ einfach ein datenparalleler Algorithmus formulieren. Nachdem sich Mehrkernprozessoren sowohl in Desktop-PCs als auch in Laptops und sogar günstigen Netbooks und Smart Phones als Standard etabliert haben ist davon auszugehen, dass eine Mehrheit der Nutzer von GEGL mehrere Threads gleichzeitig ausführen kann.  Nicht zuletzt sind insbesondere Grafikkarten hervorragend für diese Aufgabe geeignet, wurden sie doch mit Hinblick auf jenes Szenario entwickelt. Im Zuge der fortschreitenden Marktdurchdringung von OpenCL ist davon auszugehen, dass ebenso die Anzahl der Nutzer, welche von einer Portierung der Algorithmen auf die GPU profitieren würden, wachsen wird. Es ergibt sich also ein hohes Potential durch Parallelisierung die Wartezeit der meisten Nutzer zu verringern.

Unsere Gruppe hat vier Filtern von GIMP nach GEGL portiert und parallelisiert. Für die Parallelisierung auf der CPU wurden OpenMP und SSE verwendet, ein Filter wurde zudem mittels OpenCL parallelisiert.
Die vorliegende Arbeit soll sowohl unsere Vorgehensweise und Erfahrung als auch die Ergebnisse der Portierung und Parallelisierung dokumentieren. 
%Standvorher
%Zielsetzung
%Portierung von GIMP nach GEGL
%Parallelisierung mittels OpenMP

\section{Filter}
\subsection{Color Exchange}
\paragraph{Filter aus Nutzersicht}
\glqq Dieses Filter ersetzt eine Farbe durch eine andere.\grqq\footnote{\url{http://docs.gimp.org/de/plug-in-exchange.html}} -- so steht es in der Dokumentation von GIMP und fasst die Grundidee des Filters grob zusammen. Tatsächlich ermöglicht das Filter jedoch nicht nur exakt eine Farbe durch eine andere zu ersetzen, sondern auch ähnliche Farben durch eine andere zu ersetzen. Somit können auch ganze Farbverläufe unter Beibehaltung der Abstufung mit einer anderen Farbe versehen werden.

\paragraph{Algorithmus} 

Das Filter prüft für jeden Pixel im Eingabebild jeweils für jeden Farbkanal ob der Farbwert nicht mehr als um den angegebenen Grenzwert von der Auswahlfarbe abweicht. Trifft dies zu wird jeweils der Farbwert addiert mit dem positiven Betrag der Abweichung in das Ausgabebild geschrieben. Ist die Abweichung größer so wird der Wert dieses Farbkanals für jenen Pixel unverändert in das Ausgabebild übertragen. Ebenfalls unverändert bleibt der Alpha-Wert eines jeden Pixels.

\begin{algorithm}[H]
\caption{Pseudo-Code des \glqq Color Exchange\grqq-Algorithmus}
\label{algo:exchange}
\begin{algorithmic}[1]
\State $color \in \{red, green, blue\}$
\ForAll{$pixel \in input$}
  \State $\delta_{color} \gets \abs{ pixel_{color} - from_{color}}$    
  \If{$\forall color: \delta_{color} \leq threshold_{color}$}
    \ForAll{$color$}  
      \State $outputPixel_{color} \gets from_{color} + \delta_{color}$
    \EndFor
  \Else
    \ForAll{$color$}
      \State $outputPixel_{color} \gets pixel_{color}$
    \EndFor
  \EndIf
  \State $outputPixel_{alpha} \gets pixel_{alpha}$
  \State schreibe $outputPixel$ in das Ausgabebild
\EndFor
\end{algorithmic}
\end{algorithm}

\paragraph{Portierung}
Bei der Portierung wurde vorerst die Farbrepräsentation in RGBA mit 8 Bit je Farbkanal beibehalten. Ferner enthält die Implementierung innerhalb von GIMP bereits einen Fehler. Dieser wurde bei der Portierung zunächst übernommen um einen Vergleich zwischen portierter und der ursprünglichen Variante dieses Filters ziehen zu können. Die fragliche Code-Stelle findet sich in Zeile 6 von \autoref{algo:exchange}. Durch die Verwendung des Betrages der Differenz an jener Stelle führen insbesondere hohe Schwellwerte zu unerwünschten Artefakten. Der Fehler wurde bereits den GEGL-Entwicklern mitgeteilt und wird von uns zu einem späteren Zeitpunkt korrigiert.

\paragraph{Parallelisierung}
Bei diesem Filter handelt es sich um einen sogenannten Punktfilter, was bedeutet, dass ein Ausgabepixel von genau einem Eingabepixel abhängt. Somit ist keine Koordination zwischen den einzelnen Threads notwendig. Dies ist ein glücklicher Umstand für die Parallalisierung, da diese besonders einfach ausfällt. So einfach, dass diese Klasse von Problemen in der Fachsprache \glqq embarassingly parallel\grqq also etwa \glqq peinlich parallel\grqq genannt wird.

Zur Parallelisierung wurde OpenMP verwendet. Hierbei wurde das Eingabebild in Streifen auf die jeweiligen Threads aufgeteilt. Ein Thread berechnet somit jeweils einen oder mehrere Streifen aus beieinander liegenden Pixeln.

\begin{algorithm}[H]
\caption{Pseudo-Code des \glqq Color Exchange\grqq-Algorithmus in OpenMP}
\label{algo:exchange_par}
\begin{algorithmic}[1]
\State $color \in \{red, green, blue\}$
\State zerlege Bild in numThreads Teilbereiche
\State weise jedem Thread seinen Teilbereich $threadInput$ zu
\ForAll{$thread \in {1..numThreads}$}
\ForAll{$pixel \in threadInput$}
  \State $\delta_{color} \gets \abs{ pixel_{color} - from_{color}}$    
  \If{$\forall color: \delta_{color} \leq threshold_{color}$}
    \ForAll{$color$}  
      \State $outputPixel_{color} \gets from_{color} + \delta_{color}$
    \EndFor
  \Else
    \ForAll{$color$}
      \State $outputPixel_{color} \gets pixel_{color}$
    \EndFor
  \EndIf
  \State $outputPixel_{alpha} \gets pixel_{alpha}$
  \State schreibe $outputPixel$ in das Ausgabebild
\EndFor
\EndFor
\end{algorithmic}
\end{algorithm}
 
Eine weitere Möglichkeit bestünde darin jeweils die Betrachtung der Farbkanäle eines Pixels zu Parallelisieren. Diese Idee wurde jedoch als zu kleinschrittig verworfen. Der Koordinierungsaufwand für die Threads dürfte den Zeitgewinn bei der Berechnung mehr als aufwiegen. Denkbar wäre es jedoch diese Parallelisierung mittels Vektoreinheiten der CPU durchzuführen, also beispielsweise SSE zu verwenden.

Weiterhin gestaltet sich eine Parallelisierung mittels OpenCL recht einfach. Hierfür wählt man eine eindimmensionale Organisierung der Work Items und bearbeitet pro Work Item genau einen Pixel. Die äußere Schleife des sequenziellen Algorithmus fällt somit weg. Die oberen und unteren Grenzwerte werden einmal auf der CPU berechnet und der GPU als Konstanten übergeben. Diese Implementierung wäre sehr wahrscheinlich durch die Speicherbandbreite auf der GPU und durch die Bandbreite zwischen Host und GPU limitiert, da sehr wenige Berechnungen auf den Daten ausgeführt werden.



\input{gtile_part.tex}



\input{edge-neon_teil1.tex}








\subsection{Selective Gaussian Blur}
\input{selective-gaussian-blur-body.tex}
\subparagraph{OpenCL}
Dieses Filter wurde im Gegensatz zu den anderen Filtern nicht nur mittels OpenMP sondern auch mittels OpenCL parallelisiert. 



Durch die Portierung des Algorithmus nach OpenCL fielen die äußeren beiden Schleifen weg, da die Iteration über alle Pixel durch die Abbildung auf die Work Items erfolgte. Die Work Items wurden zweidimensional indiziert und es ist genau ein Work Item für genau einen Pixel zuständig.
Es wurden wo möglich Vector-Datentypen (float4) verwendet um sowohl Speicherzugriffe zu optimieren als auch um von der Nutzung der Vector-Recheneinheiten zu profitieren.

Durch die Zuordnung eines Pixels zu genau einem Work Item, wobei der Index beider identisch ist, ergibt sich ferner ein Zugriff auf den Globalen Speicher, der Speichertransfers optimiert. Benachbarte Work Items greifen auf benachbarte Speicherstellen zu. Somit kann der Speicherzugriff verschmolzen (coalesced) stattfinden was dazu führt, dass statt mehrerer kleiner Speicherzugriffe deutlich weniger größere erfolgen. Als Folge dessen wird die Speicherbandbreite besser genutzt, wodurch sich wiederum die Laufzeit verringert.

Nach der Implementierung mit jenen Optimierungen wurde die Laufzeit gemessen. Als sich herausstellte dass weitere Optimierungen kaum noch eine Verringerung der Laufzeit herbeiführen würden, da der Kernel bereits zu diesem Zeitpunkt nur noch einen kleinen Bruchteil der Gesamtlaufzeit der GEGL-Operation ausmachte (siehe Ahmdal's Law) wurde von weiteren Optimierungen abgesehen.

Weitere Ansätze zur Optimierung wären gewesen:
\begin{enumerate}
%% \item [] \begin{description} 
\item Durch die Verwendung lokalen Speichers ist es möglich die Speicherzugriffe auf den globalen Speicher zu minimieren. Da letzterer eine um Größenordnungen höhere Latenz hat als lokaler Speicher hätte man so bereits selbst bei nur einer Wiederverwendung der Daten eine insgesamt geringere Laufzeit. Hierbei ist jedoch zu beachten, dass lokaler Speicher nur in einer sehr begrenzten Größe zur Verfügung steht und jeweils nur von der Work Group verwendet werden kann, zu der er gehört. Daraus ergeben sich mehrere Konsequenzen:

Das Bild wird in mehrere Teilbilder zerlegt, deren Anzahl gleich der Zahl der Work Groups ist. Dies stellt zunächst einmal kein Problem dar. Jedoch benötigt dieses Filter für die Berechnung eines Pixels auch Pixel in seiner Umgebung. Mit zunehmender Größe dieser Umgebung, also zunehmendem Radius des Filters, erhöht sich ebenso die Redundanz der vorgehaltenen Pixel.



% Bild einfügen

Dies führt zu mehr Zugriffen auf den globalen Speicher, was somit die Laufzeit erhöht, wenn dies nicht durch Latency Hiding also das "Verschleiern" der Latenz durch die Überbrückung der Wartezeit für Speicherzugriffe durch andere Operationen vermieden werden kann.
Darüber hinaus wächst aber auch der Speicherverbrauch an lokalem Speicher. Bei großen Radien führt dies dazu, dass weniger Work Units gleichzeitig ausgeführt werden können. Dies wiederum hat einen negativen Einfluss auf das Latency Hiding, da weniger Arbeit für das Überbrücken der Wartezeiten durch Speicherzugriffe vorhanden ist. 


% Bild einfügen?

Große Radien können weiterhin dazu führen, dass die zur Berechnung notwendige Umgebung (halo) nicht vollständig in den lokalen Speicher passt. Somit wird ein aufwändigeres Speichermanagement notwendig. Die Größe des Radius ab dem diese Problematik auftritt lässt sich jedoch mit einer weiteren Optimierung zumindest erhöhen.

	Vorteil: Höhere Geschwindigkeit

	Nachteil: Höhere Code-Komplexität, maximaler Radius beschränkt


\item Eine weitere angedachte Optimierung war die Zerlegung des Filters in zwei Filter, die nacheinander aufgerufen werden. Man kann diesen Filter in eine horizontale und eine vertikale Operation zerlegen. Somit benötigt man nur noch die Umgebung in einer Ausrichtung (horizontal oder vertikal) in dem jeweiligen Filter. Dies spart Speicherzugriffe. Erschwerend kommt bei diesem Filter jedoch hinzu, dass man von einem Filter zum nächsten auch die Koeffizienten pro Pixel ebenfalls mitführen müsste -- entweder über einen seperaten Buffer oder aber gemeinsam in einem Buffer zusammen mit den Farbwerten. Ersteres ist hierbei in Hinblick auf das Speicher-Alignment vermutlich vorzuziehen, dies müsste man jedoch empirisch überprüfen.

% Bild einfügen.

\item Kombiniert man nun die Zerlegung des Filters in eine horizontalen und einen vertikalen mit der Nutzung lokalen Speichers, so ergeben sich Synergieeffekte. Es können nun die Halos größerer Radien im lokalen Speicher Platz finden.

\item Ist der Radius des Filters klein, so kann man nun zusätzlich zu den genannten Optimierungen auch noch mehrere Pixel pro Work Unit berechnen. Dies hat den Vorteil, dass sich das Verhältnis von berechneten Pixeln zu Halo-Pixeln zugunsten ersteren verschiebt. Somit verringert sich die Redundanz der im lokalen Speicher vorgehaltenen Pixel weiter und es werden weniger Daten vom globalen Speicher gelesen. Man müsste bei dieser Optimierung allerdings überprüfen wie viel lokalen Speicher man verwenden kann bevor die Laufzeit eventuell wieder steigt, da nicht mehr genug Work Items für Latency Hiding zur Verfügung stehen.
%%\end{description}
\end{enumerate}

\section{Evaluation der Ergebnisse}
\subsection{Color Exchange}
\paragraph{Korrektheit}
%Bild Eingabe (Duck / matting-global / car-stack?)
%Vergleich Ausgabe bei Eingabe mit gleichen Parametern GIMP – GEGL Bilder
%Ergebnis vom Diff
\paragraph{Laufzeit}
Verwendet man 2 OpenMP-Threads, so wird der Code minimal schneller ausgeführt\footnote{Zur Ermittlung der Laufzeit wurde der Code jeweils 50 mal ausgeführt und die Laufzeit erfasst. Das Testsystem hierfür war ein Ubuntu 13.12 auf einem Q9550 mit 8 GB RAM. Auf die Verwendung des Institusrechners für Benchmarking wurde verzichtet.}, wie in \autoref{fig:CE_2} zu sehen ist. Dieser kaum merkliche Geschwindigkeitszuwachs rechtfertigt die gestiegene Code-Komplexität jedoch in keiner Weise.

\begin{figure}[hb]
\centering
\caption{Laufzeit von Color Exchange mit einem und zwei OpenMP-Threads}
\label{fig:CE_2}
\end{figure}
Entgegen unseren Erwartungen wird dieses Filter mit zunehmender Anzahl an Threads langsamer statt schneller. Insbesondere bei der Ausführung mit 4 Threads wird dieses Verhalten besonders deutlich.(siehe \autoref{algo:exchange_par}) Somit muss die Verwendbarkeit dieser Parallelisierungsstrategie für die praktische Nutzung entschieden verneint werden.

\begin{figure}[hb]
\centering
\includegraphics[scale=0.7]{diag.pdf}
\caption{Laufzeit von Color Exchange mit einem bis vier OpenMP-Threads}
\end{figure}

\begin{table}[H]
\centering
\begin{tabular}{lrrrrr}
\toprule
 & & \multicolumn{4}{c}{OpenMP-Threads} \\
\cmidrule(r){3-6}
 & seq & 1 & 2 & 3 & 4 \\
oberes Quartil 	& 0 		& 3.39 		& 3.3720 		& 7.178 		& 53.18 \\
Median 			& 0 		& 3.39 		& 3.3785 		& 8.360 		& 54.888 \\
unteres Quartil 	& 0 		& 3.40 		& 3.3910 		& 8.973 		& 55.978 \\
\bottomrule
\end{tabular}
\caption{Laufzeit von Color Exchange in verschiedenen Konfigurationen}
\label{tab:CE_runtime}
\end{table}
%X Durchläufe in Diagram abtragen?
%System beschreiben (Hardware, Software, Umgebungsvariablen) !!!
%Boxplots !!!
%Statistische Analyse ?!
%Aus Debug-Output Diagramm erstellen um Anteil des Filters an Gesamtlaufzeit zu verdeutlichen
%\subsection{Glass Tile}
%\paragraph{Korrektheit}
%Bild Eingabe (Duck / matting-global / car-stack?)
%Vergleich Ausgabe bei Eingabe mit gleichen Parametern GIMP – GEGL Bilder
%Ergebnis vom Diff
%\paragraph{Laufzeit}
%X Durchläufe in Diagram abtragen?
%System beschreiben (Hardware, Software, Umgebungsvariablen) !!!
%Boxplots !!!
%Statistische Analyse ?!
%Aus Debug-Output Diagramm erstellen um Anteil des Filters an Gesamtlaufzeit zu verdeutlichen
\input{gtile_eval.tex}


%\subsection{Neon}
%\paragraph{Korrektheit}
%Bild Eingabe (Duck / matting-global / car-stack?)
%Vergleich Ausgabe bei Eingabe mit gleichen Parametern GIMP – GEGL Bilder
%Ergebnis vom Diff
%\paragraph{Laufzeit}
%X Durchläufe in Diagram abtragen?
%System beschreiben (Hardware, Software, Umgebungsvariablen) !!!
%Boxplots !!!
%Statistische Analyse ?!
%Aus Debug-Output Diagramm erstellen um Anteil des Filters an Gesamtlaufzeit zu verdeutlichen
\input{edge-neon_teil2.tex}




\subsection{Selective Gaussian Blur}
\paragraph{Korrektheit}
%Bild Eingabe (Duck / matting-global / car-stack?)
%Vergleich Ausgabe bei Eingabe mit gleichen Parametern GIMP – GEGL Bilder
%Ergebnis vom Diff
\paragraph{Laufzeit}
%X Durchläufe in Diagram abtragen?
%System beschreiben (Hardware, Software, Umgebungsvariablen) !!!
%Boxplots !!!
%Statistische Analyse ?!
%Aus Debug-Output Diagramm erstellen um Anteil des Filters an Gesamtlaufzeit zu verdeutlichen
%Warum wird es mit OpenMP langsamer?
\section{Abschließende Betrachtung}
Einen unerwartet großen Anteil an der aufgewandten Zeit hat die Portierung in Anspruch genommen. Insbesondere das Verständnis für die Funktionsweise von GEGL hat sich erst nach tiefgründiger Beschäftigung eingestellt. Waren dann GEGL und der zu portierende Algorithmus erst einmal verstanden lief die Portierung relativ flüssig ab. Das Tiling durch GEGL hat jedoch hin und wieder für längere Denkpausen gesorgt.
Positiv ist anzumerken, dass die Quellcode-Dateien infolge der Portierung nach GEGL deutlich übersichtlicher geworden sind, da der ganze Boiler Plate-Code, wie z.B. GUI-Erstellung und Aktualisierung, wegfällt.
Die Parallelisierung mittels OpenMP ist sicherlich nicht die optimale Lösung für GEGL-Filter, da das Tiling eigentlich ebenfalls als Parallelisierungsmechanismus vorgesehen ist. Nichtsdestotrotz 

\section{Ausblick}
%Umstellung auf Floats
%Behebung des Bugs
%Implementierung in OpenCL
\section{Grußworte}
Ich bedanke mich bei meinen Armen dafür, dass sie immer an meiner Seite waren, meinen Beinen, die mich stets gestützt haben und meinen Fingern -- auf euch konnte ich immer zählen.
%\section{Anhang}
%\lstinputlisting[caption=Color Exchange,language=C]{color-exchange.c}
\end{document}
