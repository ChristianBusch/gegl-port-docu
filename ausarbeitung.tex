\documentclass[10pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[ngerman]{babel}
\selectlanguage{ngerman}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}

\usepackage{algorithm}
\floatname{algorithm}{Algorithmus}
\usepackage[noend]{algpseudocode}
\usepackage{listings}
\lstset{language=C,stepnumber=1,numbers=left,breaklines=true}
\usepackage[shortcuts]{extdash}	% trenne auch Worte, die einen Bindestrich enthalten
\providecommand{\abs}[1]{\lvert#1\rvert}
\providecommand{\norm}[1]{\lVert#1\rVert}
\usepackage{hyperref}
\usepackage{color}
\newcommand{\algorithmautorefname}{Algorithmus}

\hyphenation{
RGBA
}

\begin{document}

\author{Christian Busch
\and
Igor Karlinskiy
\and
Oleksandr Khomenko
\and
Sascha Denis Knöpfle
}
\title{Portierung und Parallelisierung mehrerer Filter von GIMP nach GEGL}
\maketitle

\section{Einleitung}
Das Anwenden von Filtern auf Bilddaten ist ein häufiger Anwendungsfall für Parallelisierung. Hierbei muss oft ein und dieselbe Operation für jeden Pixel des Ausgabebildes angewandt werden. Somit lässt sich relativ einfach ein datenparalleler Algorithmus formulieren. Nachdem sich Mehrkernprozessoren sowohl in Desktop-PCs als auch in Laptops und sogar günstigen Netbooks und Smart Phones als Standard etabliert haben ist davon auszugehen, dass eine Mehrheit der Nutzer von GEGL mehrere Threads gleichzeitig ausführen kann.  Nicht zuletzt sind insbesondere Grafikkarten hervorragend für diese Aufgabe geeignet, wurden sie doch mit Hinblick auf jenes Szenario entwickelt. Im Zuge der fortschreitenden Marktdurchdringung von OpenCL ist davon auszugehen, dass ebenso die Anzahl der Nutzer, welche von einer Portierung der Algorithmen auf die GPU profitieren würden, wachsen wird. Es ergibt sich also ein hohes Potential durch Parallelisierung die Wartezeit der meisten Nutzer zu verringern.

Unsere Gruppe hat vier Filtern von GIMP nach GEGL portiert und parallelisiert. Für die Parallelisierung auf der CPU wurden OpenMP und SSE verwendet, ein Filter wurde zudem mittels OpenCL parallelisiert.
Die vorliegende Arbeit soll sowohl unsere Vorgehensweise und Erfahrung als auch die Ergebnisse der Portierung und Parallelisierung dokumentieren. 
%Standvorher
%Zielsetzung
%Portierung von GIMP nach GEGL
%Parallelisierung mittels OpenMP

\section{Filter}
\subsection{Color Exchange}
\paragraph{Filter aus Nutzersicht}
\glqq Dieses Filter ersetzt eine Farbe durch eine andere.\grqq\footnote{\url{http://docs.gimp.org/de/plug-in-exchange.html}} -- so steht es in der Dokumentation von GIMP und fasst die Grundidee des Filters grob zusammen. Tatsächlich ermöglicht das Filter jedoch nicht nur exakt eine Farbe durch eine andere zu ersetzen, sondern auch ähnliche Farben durch eine andere zu ersetzen. Somit können auch ganze Farbverläufe unter Beibehaltung der Abstufung mit einer anderen Farbe versehen werden.

\paragraph{Algorithmus} 

Das Filter prüft für jeden Pixel im Eingabebild jeweils für jeden Farbkanal ob der Farbwert nicht mehr als um den angegebenen Grenzwert von der Auswahlfarbe abweicht. Trifft dies zu wird jeweils der Farbwert addiert mit dem positiven Betrag der Abweichung in das Ausgabebild geschrieben. Ist die Abweichung größer so wird der Wert dieses Farbkanals für jenen Pixel unverändert in das Ausgabebild übertragen. Ebenfalls unverändert bleibt der Alpha-Wert eines jeden Pixels.

\begin{algorithm}[H]
\caption{Pseudo-Code des \glqq Color Exchange\grqq-Algorithmus}
\label{algo:exchange}
\begin{algorithmic}[1]
\ForAll{$pixel \in input$}
  \ForAll{$color \in \{red, green, blue\}$}
    \State $\delta_{color} \gets \abs{ pixel_{color} - from_{color}}$    
    \If{$\delta_{color} \leq threshold_{color}$}  
      \State $outputPixel_{color} \gets from_{color} + \delta_{color}$
    \Else
      \State $outputPixel_{color} \gets pixel_{color}$
    \EndIf
  \EndFor
  \State $outputPixel_{alpha} \gets pixel_{alpha}$
  \State write $outputPixel$ into $output$ at $pixel$'s index 
\EndFor
\end{algorithmic}
\end{algorithm}

\paragraph{Portierung}
Bei der Portierung wurde vorerst die Farbrepräsentation in RGBA mit 8 Bit je Farbkanal beibehalten. Ferner enthält die Implementierung innerhalb von GIMP bereits einen Fehler. Dieser wurde bei der Portierung vorerst übernommen um einen Vergleich zwischen portierter und der ursprünglichen Variante dieses Filters ziehen zu können. Die fragliche Code-Stelle findet sich in Zeile 5 von \autoref{algo:exchange}. Durch die Verwendung des Betrages der Differenz an jener Stelle führen insbesondere hohe Schwellwerte zu unerwünschten Artefakten. Der Fehler wurde bereits den GEGL-Entwicklern mitgeteilt und wird von uns zu einem späteren Zeitpunkt korrigiert.

\paragraph{Parallelisierung}
Bei diesem Filter handelt es sich um einen sogenannten Punktfilter, was bedeutet, dass ein Ausgabepixel von genau einem Eingabepixel abhängt. Somit ist keine Koordination zwischen den einzelnen Threads notwendig. Dies ist ein glücklicher Umstand für die Parallalisierung, da diese besonders einfach ausfällt. So einfach, dass diese Klasse von Problemen in der Fachsprache \glqq embarassingly parallel\grqq also etwa \glqq peinlich parallel\grqq genannt wird.

Zur Parallelisierung wurde OpenMP verwendet. Hierbei wurde das Eingabebild in Streifen auf die jeweiligen Threads aufgeteilt. Ein Thread berechnet somit jeweils einen oder mehrere Streifen aus beieinander liegenden Pixeln.

\begin{algorithm}[H]
\caption{Pseudo-Code des \glqq Color Exchange\grqq-Algorithmus}
\label{algo:exchange_par}
\begin{algorithmic}[1]
\State split $input$ in $numThreads$ parts
\ForAll{$thread \in \{0, \ldots, numThreads - 1\}$}
  
  \ForAll{$pixel \in input$}
    \ForAll{$color \in \{red, green, blue\}$}
      \State $\delta_{color} \gets \abs{ pixel_{color} - from_{color}}$    
      \If{$\delta_{color} \leq threshold_{color}$}  
        \State $outputPixel_{color} \gets from_{color} + \delta_{color}$
      \Else
        \State $outputPixel_{color} \gets pixel_{color}$
      \EndIf
    \EndFor
    \State $outputPixel_{alpha} \gets pixel_{alpha}$
    \State write $outputPixel$ into $output$ at $pixel$'s index 
  \EndFor
\EndFor
\end{algorithmic}
\end{algorithm}
 
Eine weitere Möglichkeit bestünde darin jeweils die Betrachtung der Farbkanäle eines Pixels zu Parallelisieren. Diese Idee wurde jedoch als zu kleinschrittig verworfen. Der Koordinierungsaufwand für die Threads dürfte den Zeitgewinn bei der Berechnung mehr als aufwiegen. Denkbar wäre es jedoch diese Parallelisierung mittels Vektoreinheiten der CPU durchzuführen, also beispielsweise SSE zu verwenden.

Weiterhin gestaltet sich eine Parallelisierung mittels OpenCL recht einfach. Hierfür wählt man eine eindimmensionale Organisierung der Work Items und bearbeitet pro Work Item genau einen Pixel. Die äußere Schleife des sequenziellen Algorithmus fällt somit weg. Die oberen und unteren Grenzwerte werden einmal auf der CPU berechnet und der GPU als Konstanten übergeben. Diese Implementierung wäre sehr wahrscheinlich durch die Speicherbandbreite auf der GPU und durch die Bandbreite zwischen Host und GPU limitiert, da sehr wenige Berechnungen auf den Daten ausgeführt werden.

\subsection{Glass Tile}
\paragraph{Filter aus Nutzersicht}


\paragraph{Algorithmus} 

%Beschreibung Algorithmus allgemeinsprachlich, 
%Pseudocode, visuell
\paragraph{Portierung}
\paragraph{Parallelisierung}



\subsection{Neon}
\paragraph{Filter aus Nutzersicht}
Dieses Filter extrahiert Kanten in der aktiven Ebene oder Auswahl und 
umgibt diese mit einem neonartigen Glühen.

\paragraph{Algorithmus} 
Der Algorithmus besteht aus 2 großen Schleifen (detallierterer Pseudo-Code 
ist in Algorithmus \ref{algo:neon} zu finden).
Beide Suchstufen (in jeder Schleife) erfolgen spalten- bzw. zeilenweise und zwar von beiden Seiten simultan,
so ist in diesem Fall recht unbeliebte automatische Kachelnzerlegung sehr vorteilhaft, da sie Wahrscheinlichkeit dafür erhöht, dass die zum Mergen benötigten Werte noch in Cache zu finden sind.

Für weitere Details siehe Paragraph ``Parallelisierung''.


\begin{algorithm}[h]
\caption{Pseudo-Code des \glqq Neon\grqq-Algorithmus}
\label{algo:neon}
\begin{algorithmic}[1]
\ForAll{$columns \in input$}
	\State lese eine Spalte aus dem Eingabebild
	\ForAll{$pixel \in column$}
		\State berechne neon von oben nach unten
	\EndFor
	\ForAll{$pixel \in column$}
		\State berechne neon von unten nach oben
	\EndFor
	\State merge Ergebnisse in eine Spalte
	\State speichere in Ausgabebild
\EndFor	
\ForAll{$rows \in input$}
	\State lese eine Zeile aus dem Eingabebild
	\ForAll{$pixel \in row$}
		\State berechne neon von links nach rechts
	\EndFor
	\ForAll{$pixel \in row$}
		\State berechne neon von rechts nach links
	\EndFor	
	\State merge Ergebnisse in eine Zeile
	\State \label{neon_datenabhaengigkeit} bilde Gradient von dieser Zeile und einer aus dem Ausgabebild
	\State speichere in Ausgabebild
\EndFor
\end{algorithmic}
\end{algorithm}
%Beschreibung Algorithmus allgemeinsprachlich, 
%Pseudocode, visuell
\paragraph{Portierung}
\label{neon_portierung}
1) Einige unnötige Sprachkonstrukte entfernt
2) Auch viele Variablen umbenannt
\paragraph{Parallelisierung}
Es gab auch ursprünglich keine funktionale Abhängigkeit zwischen den beiden Stufen (Schritt 1 und 2),  jedoch ließ sich der Algorithmus trotzdem nur bedingt parallelisieren. Grund dafür war eine Datenabhängigkeit: In der \ref{neon_datenabhaengigkeit}. Zeile des Algorithmus \ref{algo:neon} werden Ergebnisse beider Schritte zusammengeführt. Im sequenziellen Fall hätte es einen guten Grund - bessere Cacheausnutzung - ein der beiden benötigten Felder ist garantiert im Cache (so weit Cache reicht) vorhanden.

========================================

Wird der Algorithmus parallel ausgeführt, so muss diese Datenabhängigkeit z.B. durch zusätzliche temporäre Variablen eliminiert werden. 

========================================

Ursprünglich verfolgten wir den SECTIONS-Ansatz, aber schlechtere Cacheausnutzung. Aus diesem testen wir auch den anderen Ansatz: 1. Schleife ``parallel for'', anschließend (mit impliziter Barriere) die 2. Schleife ``parallel for''.

=======================================

Kritischer Bereich (lese und schreibe in Ausgabebild) wird hier zum Flaschenhals, so mit zunehmender Threadzahl darf die Effizienz schnell fallen.

=======================================


Parallelisierbarkeit:
Der Algorithmus sieht folgender Weise aus:
	1) zum Anfang erfolgt waagerechte Suche 
	2) dann Senkrechte,
	3) zum Schluss werden beide Ergebnisse gemergt



\subsection{Selective Gaussian Blur}
\paragraph{Filter aus Nutzersicht}
\paragraph{Algorithmus} 
%Beschreibung Algorithmus allgemeinsprachlich, 
%Pseudocode, visuell
\paragraph{Portierung}
\paragraph{Parallelisierung}
\subparagraph{OpenMP}
\subparagraph{OpenCL}
Dieses Filter wurde im Gegensatz zu den anderen Filtern nicht nur mittels OpenMP sondern auch mittels OpenCL parallelisiert. 



Durch die Portierung des Algorithmus nach OpenCL fielen die äußeren beiden Schleifen weg, da die Iteration über alle Pixel durch die Abbildung auf die Work Items erfolgte. Die Work Items wurden zweidimensional indiziert und es ist genau ein Work Item für genau einen Pixel zuständig.
Es wurden wo möglich Vector-Datentypen (float4) verwendet um sowohl Speicherzugriffe zu optimieren als auch um von der Nutzung der Vector-Recheneinheiten zu profitieren.

Durch die Zuordnung eines Pixels zu genau einem Work Item, wobei der Index beider identisch ist, ergibt sich ferner ein Zugriff auf den Globalen Speicher, der Speichertransfers optimiert. Benachbarte Work Items greifen auf benachbarte Speicherstellen zu. Somit kann der Speicherzugriff verschmolzen (coalesced) stattfinden was dazu führt, dass statt mehrerer kleiner Speicherzugriffe deutlich weniger größere erfolgen. Als Folge dessen wird die Speicherbandbreite besser genutzt, wodurch sich wiederum die Laufzeit verringert.

Nach der Implementierung mit jenen Optimierungen wurde die Laufzeit gemessen. Als sich herausstellte dass weitere Optimierungen kaum noch eine Verringerung der Laufzeit herbeiführen würden, da der Kernel bereits zu diesem Zeitpunkt nur noch einen kleinen Bruchteil der Gesamtlaufzeit der GEGL-Operation ausmachte (siehe Ahmdal's Law) wurde von weiteren Optimierungen abgesehen.

Weitere Ansätze zur Optimierung wären gewesen:

Verwendung lokalen Speichers. Durch die Verwendung lokalen Speichers ist es möglich die Speicherzugriffe auf den globalen Speicher zu minimieren. Da letzterer eine um Größenordnungen höhere Latenz hat als lokaler Speicher hätte man so bereits selbst bei nur einer Wiederverwendung der Daten eine insgesamt geringere Laufzeit. Hierbei ist jedoch zu beachten, dass lokaler Speicher nur in einer sehr begrenzten Größe zur Verfügung steht und jeweils nur von der Work Group verwendet werden kann, zu der er gehört. Daraus ergeben sich mehrere Konsequenzen:

Das Bild wird in mehrere Teilbilder zerlegt, deren Anzahl gleich der Zahl der Work Groups ist. Dies stellt zunächst einmal kein Problem dar. Jedoch benötigt dieses Filter für die Berechnung eines Pixels auch Pixel in seiner Umgebung. Mit zunehmender Größe dieser Umgebung, also zunehmendem Radius des Filters, erhöht sich ebenso die Redundanz der vorgehaltenen Pixel.

% Bild einfügen

Dies führt zu mehr Zugriffen auf den globalen Speicher, was somit die Laufzeit erhöht, wenn dies nicht durch Latency Hiding also das "Verschleiern" der Latenz durch die Überbrückung der Wartezeit für Speicherzugriffe durch andere Operationen vermieden werden kann.
Darüber hinaus wächst aber auch der Speicherverbrauch an lokalem Speicher. Bei großen Radien führt dies dazu, dass weniger Work Units gleichzeitig ausgeführt werden können. Dies wiederum hat einen negativen Einfluss auf das Latency Hiding, da weniger Arbeit für das Überbrücken der Wartezeiten durch Speicherzugriffe vorhanden ist. 


% Bild einfügen?

Große Radien können weiterhin dazu führen, dass die zur Berechnung notwendige Umgebung (halo) nicht vollständig in den lokalen Speicher passt. Somit wird ein aufwändigeres Speichermanagement notwendig. Die Größe des Radius ab dem diese Problematik auftritt lässt sich jedoch mit einer weiteren Optimierung zumindest erhöhen.


Eine weitere angedachte Optimierung war die Zerlegung des Filters in zwei Filter, die nacheinander aufgerufen werden. Man kann diesen Filter in eine horizontale und eine vertikale Operation zerlegen. Somit benötigt man nur noch die Umgebung in einer Ausrichtung (horizontal oder vertikal) in dem jeweiligen Filter. Dies spart Speicherzugriffe.

% Bild einfügen.

Kombiniert man nun die Zerlegung des Filters in eine horizontalen und einen vertikalen so ergeben sich Synergieeffekte. Es können nun die Halos größerer Radien im lokalen Speicher Platz finden. Erschwerend kommt bei diesem Filter jedoch hinzu, dass man von einem Filter zum nächsten auch die Koeffizienten pro Pixel ebenfalls mitführen müsste -- entweder über einen seperaten Buffer oder aber gemeinsam in einem Buffer zusammen mit den Farbwerten. Ersteres ist hierbei in Hinblick auf das Speicher-Alignment vermutlich vorzuziehen, dies müsste man jedoch empirisch überprüfen.

Ist der Radius des Filters klein, so kann man nun zusätzlich zu den genannten Optimierungen auch noch mehrere Pixel pro Work Unit berechnen. Dies hat den Vorteil, dass sich das Verhältnis von berechneten Pixeln zu Halo-Pixeln zugunsten ersteren verschiebt. Somit verringert sich die Redundanz der im lokalen Speicher vorgehaltenen Pixel weiter und es werden weniger Daten vom globalen Speicher gelesen. Man müsste bei dieser Optimierung allerdings überprüfen wie viel lokalen Speicher man verwenden kann bevor die Laufzeit eventuell wieder steigt, da nicht mehr genug Work Items für Latency Hiding zur Verfügung stehen.

\section{Evaluation der Ergebnisse}
\subsection{Color Exchange}
\paragraph{Korrektheit}
%Bild Eingabe (Duck / matting-global / car-stack?)
%Vergleich Ausgabe bei Eingabe mit gleichen Parametern GIMP – GEGL Bilder
%Ergebnis vom Diff
\paragraph{Laufzeit}
%X Durchläufe in Diagram abtragen?
%System beschreiben (Hardware, Software, Umgebungsvariablen) !!!
%Boxplots !!!
%Statistische Analyse ?!
%Aus Debug-Output Diagramm erstellen um Anteil des Filters an Gesamtlaufzeit zu verdeutlichen
\subsection{Glass Tile}
\paragraph{Korrektheit}
%Bild Eingabe (Duck / matting-global / car-stack?)
%Vergleich Ausgabe bei Eingabe mit gleichen Parametern GIMP – GEGL Bilder
%Ergebnis vom Diff
\paragraph{Laufzeit}
%X Durchläufe in Diagram abtragen?
%System beschreiben (Hardware, Software, Umgebungsvariablen) !!!
%Boxplots !!!
%Statistische Analyse ?!
%Aus Debug-Output Diagramm erstellen um Anteil des Filters an Gesamtlaufzeit zu verdeutlichen
\subsection{Neon}
\paragraph{Korrektheit}
%Bild Eingabe (Duck / matting-global / car-stack?)
%Vergleich Ausgabe bei Eingabe mit gleichen Parametern GIMP – GEGL Bilder
%Ergebnis vom Diff
\paragraph{Laufzeit}
%X Durchläufe in Diagram abtragen?
%System beschreiben (Hardware, Software, Umgebungsvariablen) !!!
%Boxplots !!!
%Statistische Analyse ?!
%Aus Debug-Output Diagramm erstellen um Anteil des Filters an Gesamtlaufzeit zu verdeutlichen
\subsection{Selective Gaussian Blur}
\paragraph{Korrektheit}
%Bild Eingabe (Duck / matting-global / car-stack?)
%Vergleich Ausgabe bei Eingabe mit gleichen Parametern GIMP – GEGL Bilder
%Ergebnis vom Diff
\paragraph{Laufzeit}
%X Durchläufe in Diagram abtragen?
%System beschreiben (Hardware, Software, Umgebungsvariablen) !!!
%Boxplots !!!
%Statistische Analyse ?!
%Aus Debug-Output Diagramm erstellen um Anteil des Filters an Gesamtlaufzeit zu verdeutlichen
%Warum wird es mit OpenMP langsamer?
\section{Ausblick}
%Umstellung auf Floats
%Behebung des Bugs
%Implementierung in OpenCL
\section{Grußworte}
Ich bedanke mich bei meinen Armen dafür, dass sie immer an meiner Seite waren, meinen Beinen, die mich stets gestützt haben und meinen Fingern -- auf euch konnte ich immer zählen.
%\section{Anhang}
%\lstinputlisting[caption=Color Exchange,language=C]{color-exchange.c}
\end{document}